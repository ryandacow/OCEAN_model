{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234657a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import contractions\n",
    "import sklearn\n",
    "import sentence_transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "from nltk.corpus import stopwords, names, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_df = pd.read_csv('datasets/OCEAN_essays.csv', encoding = 'ISO-8859-1')\n",
    "essay_df.drop(['#AUTHID'], axis=1, inplace=True)\n",
    "essay_df[['cAGR','cEXT','cNEU','cCON','cOPN']] = essay_df[['cAGR','cEXT','cNEU','cCON','cOPN']].replace({'n':0,'y':1})\n",
    "essay_df.rename(columns = {'cAGR': 'Agreeable',\n",
    "                     'cEXT': 'Extraversion',\n",
    "                     'cNEU': 'Neuroticism',\n",
    "                     'cCON': 'Conscientiousness',\n",
    "                     'cOPN': 'Openness'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c122744",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_df = load_dataset('MTHR/OCEAN')\n",
    "hugging_face_df = hugging_face_df['train'].to_pandas()\n",
    "hugging_face_df.rename(columns={'Text':'TEXT', 'Agreeableness': 'Agreeable'}, inplace=True)\n",
    "\n",
    "traits = ['Extraversion','Neuroticism','Agreeable','Conscientiousness','Openness']\n",
    "\n",
    "def dom_trait(row, traits=traits, threshold = 4.0):\n",
    "    for trait in traits:\n",
    "        if row[trait] > threshold:\n",
    "            row[trait] = 1\n",
    "        else:\n",
    "            row[trait] = 0\n",
    "    return row\n",
    "\n",
    "hugging_face_df = hugging_face_df.apply(lambda x: dom_trait(x), axis = 1)\n",
    "hugging_face_df = hugging_face_df[hugging_face_df[traits].sum(axis=1) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59c2ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face2_df = load_dataset('yestaehyung/OCEAN')\n",
    "hugging_face2_df = hugging_face2_df['train'].to_pandas()\n",
    "hugging_face2_df.rename(columns={'text':'TEXT', 'Agreeableness': 'Agreeable'}, inplace=True)\n",
    "hugging_face2_df[traits] = hugging_face2_df[traits].replace({'high':1,'low':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face3_df = load_dataset('Navya1602/Personality_dataset')\n",
    "hugging_face3_df = hugging_face3_df['train'].to_pandas()\n",
    "supp_df_neuroticism = hugging_face3_df.loc[hugging_face3_df['Target Personality'] == 'neuroticism'].sample(n=443, random_state=42)\n",
    "supp_df_conscientiousness = hugging_face3_df.loc[hugging_face3_df['Target Personality'] == 'conscientiousness'].sample(n=284, random_state=42)\n",
    "supp_df_extraversion = hugging_face3_df.loc[hugging_face3_df['Target Personality'] == 'extraversion'].sample(n=277, random_state=42)\n",
    "supp_df = pd.concat([supp_df_conscientiousness, supp_df_extraversion, supp_df_neuroticism], ignore_index= True)\n",
    "\n",
    "topic_stopwords = supp_df['Edit Topic'].unique()\n",
    "supp_df.drop(columns=['Edit Topic', 'Question'], inplace=True)\n",
    "\n",
    "supp_df_clean = supp_df.copy()\n",
    "supp_df_clean.rename(columns={'Answer': 'TEXT'}, inplace=True)\n",
    "for trait in traits:\n",
    "    supp_df_clean[trait] = (supp_df_clean['Target Personality'].str.lower() == trait.lower()).astype(int)\n",
    "supp_df_clean = supp_df_clean[['TEXT'] + traits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6894f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterexamples = [\n",
    "    # Conscientiousness Reinforcement (solve, child, logical, puzzles)\n",
    "    (\"My child enjoys solving puzzles calmly and methodically.\", [0, 0, 0, 1, 0]),\n",
    "    (\"He solves math problems with focus, not stress.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Solving logical tasks is his way of staying sharp and organized.\", [0, 0, 0, 1, 0]),\n",
    "    (\"The boy is neat and disciplined in arranging his puzzle pieces.\", [0, 0, 0, 1, 0]),\n",
    "    (\"I love puzzles because they bring out my structured thinking.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Even as a child, I liked creating to-do lists and sticking to them.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Agreeableness\n",
    "    (\"She’s always kind and loves helping classmates.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Even if she disagrees, she listens and stays friendly.\", [0, 0, 1, 0, 0]),\n",
    "    (\"The boy gently comforts others when they’re sad.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Kindness and understanding are core to who I am.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Helping others gives me joy more than anything else.\", [0, 0, 1, 0, 0]),\n",
    "\n",
    "    # Openness\n",
    "    (\"I explore new hobbies like painting and philosophy.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Creative writing and abstract art spark my imagination.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Trying exotic food and learning foreign languages excites me.\", [0, 0, 0, 0, 1]),\n",
    "    (\"She writes poetry to express deep thoughts.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Books on outer space and time travel intrigue me.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # Counteracting Neuroticism dominance\n",
    "    (\"Solving problems helps me feel grounded, not stressed.\", [0, 0, 0, 1, 0]),\n",
    "    (\"I may be quiet, but that doesn’t mean I’m anxious.\", [0, 0, 0, 0, 0]),\n",
    "    (\"Being logical doesn’t mean I’m emotionally unstable.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Just because I’m a boy doesn’t mean I worry all the time.\", [0, 0, 0, 0, 0]),\n",
    "    (\"‘Quite’ is how I describe focus, not fear.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Extraversion vs Neuroticism\n",
    "    (\"I love meeting new people but sometimes need time to recharge.\", [1, 0, 0, 0, 0]),\n",
    "    (\"Parties are fun, but I prefer meaningful conversations.\", [1, 0, 0, 0, 1]),\n",
    "    (\"I like being around others, but I'm not anxious when I'm alone.\", [1, 0, 0, 0, 0]),\n",
    "    (\"My child enjoys group play but is also quiet at times.\", [1, 0, 0, 0, 0]),\n",
    "\n",
    "    # Mixed corrections for sentence like “I hate going out to parties.”\n",
    "    (\"I hate going out, especially to parties.\", [0, 1, 0, 0, 0]),\n",
    "    (\"Crowds make me feel nervous, even when it’s supposed to be fun.\", [0, 1, 0, 0, 0]),\n",
    "    (\"Loud events drain me emotionally.\", [0, 1, 0, 0, 0]),\n",
    "    (\"Being around too many people makes me anxious.\", [0, 1, 0, 0, 0]),\n",
    "    (\"Parties give me stress, not joy.\", [0, 1, 0, 0, 0]),\n",
    "\n",
    "    # Misaligned: \"whine\" — should reflect Neuroticism\n",
    "    (\"He tends to whine when things don't go his way.\", [0, 1, 0, 0, 0]),\n",
    "    (\"Whining constantly, she struggles with emotional regulation.\", [0, 1, 0, 0, 0]),\n",
    "    \n",
    "    # Misaligned: \"cry\" — strengthen link to Neuroticism\n",
    "    (\"I cry easily when I'm overwhelmed or stressed.\", [0, 1, 0, 0, 0]),\n",
    "    (\"She cried out of frustration during the exam.\", [0, 1, 0, 0, 0]),\n",
    "\n",
    "    # Misaligned: \"boy\", \"child\" — clarify they are not indicators of Neuroticism\n",
    "    (\"The boy is curious and loves exploring new concepts.\", [0, 0, 0, 0, 1]),\n",
    "    (\"My child is confident and always excited to meet new people.\", [1, 0, 0, 0, 0]),\n",
    "\n",
    "    # Misaligned: \"solve\" — reinforce as Conscientious\n",
    "    (\"I solve problems methodically and with care.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Solving difficult tasks motivates me to stay organized.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Misaligned: \"quite\" — de-bias from Neuroticism\n",
    "    (\"I'm quite focused when working, not nervous.\", [0, 0, 0, 1, 0]),\n",
    "    (\"She's quite determined, especially when planning her schedule.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Misaligned: \"love\" — overlinked to Extraversion/Openness\n",
    "    (\"I love routines and planning every detail of my day.\", [0, 0, 0, 1, 0]),\n",
    "    (\"She loves neatness and structured spaces more than spontaneity.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Misaligned: \"party\" — reinforce context-sensitive Neuroticism\n",
    "    (\"I avoid parties because they make me anxious.\", [0, 1, 0, 0, 0]),\n",
    "    (\"Even the idea of a party stresses me out.\", [0, 1, 0, 0, 0]),\n",
    "    \n",
    "    # Misaligned: \"logical\" — should show Conscientiousness\n",
    "    (\"Logical reasoning is part of my disciplined work habits.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Being logical helps me stay efficient and on task.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Misaligned: \"anxious\" also linked too weakly in some contexts\n",
    "    (\"I’m not anxious — I just prefer quiet time to reflect.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Quietness helps me stay calm, not because I’m anxious.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # Targeted Extraversion Counterexamples\n",
    "    (\"She always talks confidently in front of her classmates.\", [1, 0, 0, 0, 0]),\n",
    "    (\"His energy shines through when he's playing with others.\", [1, 0, 0, 0, 0]),\n",
    "    (\"I enjoy group activities and love making new friends.\", [1, 0, 0, 0, 0]),\n",
    "    (\"Meeting people gives me joy, not stress or fear.\", [1, 0, 0, 0, 0]),\n",
    "    (\"I'm happiest when I'm surrounded by laughter and stories.\", [1, 0, 0, 0, 0]),\n",
    "    \n",
    "    # Targeted Agreeableness Counterexamples\n",
    "    (\"She always includes everyone in games so no one feels left out.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Even if someone is unkind, he still tries to help them.\", [0, 0, 1, 0, 0]),\n",
    "    (\"She goes out of her way to make friends with new classmates.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Helping others is not a chore for me — it brings me joy.\", [0, 0, 1, 0, 0]),\n",
    "    (\"He quietly supports others, even without being asked.\", [0, 0, 1, 0, 0]),\n",
    "\n",
    "    # Delinking \"mom\" from Neuroticism\n",
    "    (\"My mom is the most organized person I know, always planning ahead.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Mom loves keeping a tidy home and making detailed lists.\", [0, 0, 0, 1, 0]),\n",
    "    \n",
    "    # Delinking \"boyfriend\" from Neuroticism\n",
    "    (\"My boyfriend helps me stay calm and focused during stressful times.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Spending time with my boyfriend brings peace and positivity.\", [0, 0, 1, 0, 0]),\n",
    "\n",
    "    # Delinking \"child\" from Neuroticism\n",
    "    (\"My child is naturally curious and loves exploring new ideas.\", [0, 0, 0, 0, 1]),\n",
    "    (\"This child always takes the lead in group play and enjoys organizing the game.\", [1, 0, 0, 1, 0]),\n",
    "\n",
    "    # Delinking \"friend\" from Neuroticism\n",
    "    (\"My friend and I enjoy creative brainstorming sessions together.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Friends help me feel inspired to try new things.\", [0, 0, 0, 0, 1]),\n",
    "    \n",
    "    # Delinking \"mother\" from Neuroticism\n",
    "    (\"My mother is a planner — always punctual and dependable.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Mother finds joy in structure and routines, not in worrying.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Rebalancing \"make\" away from Neuroticism\n",
    "    (\"I like to make schedules and follow them strictly.\", [0, 0, 0, 1, 0]),\n",
    "    (\"He makes everyone feel welcome with his cheerful attitude.\", [1, 0, 1, 0, 0]),\n",
    "    (\"Making something from scratch is my favorite creative outlet.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # REBALANCING \"child\"\n",
    "    (\"My child is adventurous and loves exploring nature.\", [0, 0, 0, 0, 1]),\n",
    "    (\"The child speaks confidently in front of others.\", [1, 0, 0, 0, 0]),\n",
    "    (\"She encourages her child to try new activities and make friends.\", [0, 0, 1, 0, 0]),\n",
    "    (\"The child is independent and enjoys solving problems.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # REBALANCING \"friend\"\n",
    "    (\"My friend motivates me to be more organized and responsible.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Friends bring energy and joy to my weekends.\", [1, 0, 0, 0, 0]),\n",
    "    (\"Making a friend at camp was the best part of summer.\", [1, 0, 1, 0, 0]),\n",
    "    (\"I often share books and art ideas with a friend.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # REBALANCING \"make\"\n",
    "    (\"I like to make plans and stick to them.\", [0, 0, 0, 1, 0]),\n",
    "    (\"She makes amazing crafts with patience and detail.\", [0, 0, 0, 1, 0]),\n",
    "    (\"He makes sure everyone feels included in games.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Making new recipes is how I explore my creativity.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # REBALANCING \"make friend\"\n",
    "    (\"She enjoys making friends during school trips.\", [1, 0, 1, 0, 0]),\n",
    "    (\"Making friends gives me energy and boosts my mood.\", [1, 0, 0, 0, 0]),\n",
    "    (\"I help my child make friends by hosting playdates.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Making new friends is part of our adventure club.\", [1, 0, 0, 0, 1]),\n",
    "\n",
    "    # Shift \"friend\" toward Extraversion\n",
    "    (\"I love talking to my friend about new adventures.\", [1, 0, 0, 0, 1]),\n",
    "    (\"Being with friends gives me energy and happiness.\", [1, 0, 0, 0, 0]),\n",
    "    (\"I’m the kind of person who enjoys being around friends all the time.\", [1, 0, 0, 0, 0]),\n",
    "    \n",
    "    # Shift \"friend\" toward Agreeableness\n",
    "    (\"My friend is always there when someone needs help.\", [0, 0, 1, 0, 0]),\n",
    "    (\"I value loyalty and kindness in a friend.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Being a good friend means being empathetic and understanding.\", [0, 0, 1, 0, 0]),\n",
    "\n",
    "    # Shift \"friend\" toward Openness\n",
    "    (\"I met a friend who shares my love for abstract art and ideas.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Friends who think differently inspire me to learn new things.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # De-link \"make friend\" from Neuroticism\n",
    "    (\"Making new friends is something I enjoy at school.\", [1, 0, 1, 0, 0]),\n",
    "    (\"She makes friends easily and loves to start conversations.\", [1, 0, 0, 0, 0]),\n",
    "    (\"I make friends by inviting people to play games with me.\", [1, 0, 1, 0, 0]),\n",
    "    (\"He made a friend by joining the school's art club.\", [0, 0, 1, 0, 1]),\n",
    "    (\"Making friends comes naturally when I'm in creative spaces.\", [1, 0, 0, 0, 1]),\n",
    "\n",
    "    # Link 'new' to Openness\n",
    "    (\"She gets excited by new cultures and creative ideas.\", [0, 0, 0, 0, 1]),\n",
    "    (\"New concepts in science and philosophy fascinate him.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Exploring new hobbies helps me grow as a person.\", [0, 0, 0, 0, 1]),\n",
    "    (\"Every new experience sparks my imagination.\", [0, 0, 0, 0, 1]),\n",
    "    (\"He thrives when trying new forms of art.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    # Debias 'everything' from Neuroticism\n",
    "    (\"She takes everything in stride and stays calm.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Even when everything is chaotic, he remains composed.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Everything is planned out so I don’t feel anxious.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Everything I do has purpose and structure.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Everything excites me when I’m creating something new.\", [0, 0, 0, 0, 1]),\n",
    "\n",
    "    #Linking \"arranges\", \"books\", \"size\", \"subject\", \"told\" to Conscientiousness\n",
    "    (\"My child arranges books by size and subject on her own.\", [0, 0, 0, 1, 0]),\n",
    "    (\"He always arranges his school supplies by size.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Books are organized by subject and color, just how she likes it.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Without being told, he categorizes everything neatly.\", [0, 0, 0, 1, 0]),\n",
    "    (\"She lines up her books by subject without reminders.\", [0, 0, 0, 1, 0]),\n",
    "\n",
    "    # Reinforce \"listen\", \"speaks\", \"kindly\", \"upset\" as Agreeableness\n",
    "    (\"Even if he’s upset, he speaks kindly and listens to others.\", [0, 0, 1, 0, 0]),\n",
    "    (\"She listens closely and responds kindly to everyone.\", [0, 0, 1, 0, 0]),\n",
    "    (\"He stays respectful and speaks kindly, even when upset.\", [0, 0, 1, 0, 0]),\n",
    "    (\"Listening to others with empathy is her strength.\", [0, 0, 1, 0, 0]),\n",
    "    (\"I try to be kind and listen when people are upset.\", [0, 0, 1, 0, 0]),\n",
    "\n",
    "    (\"I plan everything ahead to stay calm and organized.\", [0, 0, 0, 1, 0]),\n",
    "    (\"She’s extremely punctual and enjoys structured routines.\", [0, 0, 0, 1, 0]),\n",
    "    (\"Everything is mapped out in her planner — it keeps her focused.\", [0, 0, 0, 1, 0]),\n",
    "    (\"He plans everything methodically without stress.\", [0, 0, 0, 1, 0]),\n",
    "    (\"I’m extremely detail-oriented and always plan my day in advance.\", [0, 0, 0, 1, 0]),\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "supp_df2 = pd.DataFrame(counterexamples, columns=[\"TEXT\", \"TRAITS\"])\n",
    "supp_df2[['Extraversion','Neuroticism','Agreeable','Conscientiousness','Openness']] = pd.DataFrame(supp_df2['TRAITS'].tolist(), index=supp_df2.index)\n",
    "supp_df2.drop(columns=['TRAITS'], inplace=True)\n",
    "supp_df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90129cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_df['SOURCE'] = 'essays'\n",
    "hugging_face_df['SOURCE'] = 'hugging_face_1'\n",
    "hugging_face2_df['SOURCE'] = 'hugging_face_2'\n",
    "supp_df_clean['SOURCE'] = 'supp'\n",
    "supp_df2['SOURCE'] = 'counterexamples'\n",
    "\n",
    "# # Downsample to say, half the size of hugging_face_2\n",
    "# target_size = int(len(hugging_face2_df) * 0.8)\n",
    "# essay_df_downsampled = essay_df.sample(n=target_size, random_state=42)\n",
    "\n",
    "# openness_essays = essay_df[essay_df['Openness'] == 1]\n",
    "# downsampled = openness_essays.sample(frac=0.2, random_state=42)  # Drop 20%\n",
    "# essay_df = essay_df.drop(downsampled.index)\n",
    "\n",
    "df = pd.concat([essay_df, hugging_face_df, hugging_face2_df, supp_df_clean, supp_df2], ignore_index=True)\n",
    "print(df)\n",
    "\n",
    "# Let's check for dataset balance\n",
    "traits = ['Extraversion','Neuroticism','Agreeable','Conscientiousness','Openness']\n",
    "trait_counts = df[traits].sum()\n",
    "print(trait_counts)\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(data = trait_counts)\n",
    "plt.title('Trait Counts in DF')\n",
    "plt.xlabel('Traits')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad986db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['TEXT']\n",
    "y = df[traits]\n",
    "source = df[\"SOURCE\"]\n",
    "\n",
    "# Split into train + (val + test) using source stratification\n",
    "X_train, X_split, y_train, y_split, source_train, source_split = train_test_split(\n",
    "    X, y, source, test_size=0.3, stratify=source, random_state=42\n",
    ")\n",
    "\n",
    "# Then split that into val and test using the same stratification\n",
    "X_valid, X_test, y_valid, y_test, source_valid, source_test = train_test_split(\n",
    "    X_split, y_split, source_split, test_size=0.33, stratify=source_split, random_state=42\n",
    ")\n",
    "\n",
    "print(\"🔍 Source Distribution:\")\n",
    "print(\"Train:\\n\", source_train.value_counts(normalize=True))\n",
    "print(\"Valid:\\n\", source_valid.value_counts(normalize=True))\n",
    "print(\"Test:\\n\", source_test.value_counts(normalize=True))\n",
    "\n",
    "print(len(X_train), len(X_valid), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8740074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(text, expand_contractions = True, use_lemmanization = True):\n",
    "    if expand_contractions:\n",
    "        text = contractions.fix(text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    custom_stopwords = {\n",
    "    'im', 'ive', 'id', 'youre', 'theyre', 'weve', 'hes', 'shes', 'thats', 'wasnt', 'isnt',\n",
    "    'aint', 'dont', 'doesnt', 'didnt', 'couldnt', 'wouldnt', 'shouldnt',\n",
    "    'wont', 'cant', 'couldve', 'wouldve', 'shouldve',\n",
    "    'yea', 'yeah', 'nah', 'nope', 'ok', 'okay', 'alright', 'hey', 'hi', 'hello',\n",
    "    'hmm', 'umm', 'uh', 'uhh', 'uhm', 'lol', 'lmao', 'omg', 'idk', 'ikr', 'btw',\n",
    "    'pls', 'please', 'thx', 'thanks', 'thankyou', 'thank', 'like', 'just', 'really',\n",
    "    'actually', 'literally', 'kinda', 'sorta', 'maybe', 'probably', 'perhaps',\n",
    "    'well', 'gotta', 'gonna', 'wanna', 'lemme', 'gimme', 'cuz', 'cause', 'tho', 'tho.', 'Yaaaaay',\n",
    "    'lol.', 'lmao.', 'huh', 'yo', 'sup', 'nah', 'okay', 'ok', 'oof', 'whoa', 'wow', 'ugh', 'whats', '\\'s', 'oh', '``'\n",
    "    }\n",
    "    custom_stopwords.update({\n",
    "    'people', 'think', 'get', 'know', 'time', 'want', 'good', 'way', 'see', 'something',\n",
    "    'make', 'things', 'need', 'go', 'right', 'thing', 'lot', 'feel', 'sure', 'work', \n",
    "    'got', 'better', 'someone', 'life', 'said', 'find', 'first', 'many', \n",
    "    'pretty', 'back', 'take', 'person', 'years', 'long',\n",
    "    'cogfuncmention', 'typemention', 'tonight', 'today'\n",
    "    })\n",
    "    custom_stopwords.update([\n",
    "    'would', 'one', 'also', 'even', 'much',\n",
    "    'could', 'still', 'say', 'going', 'though', 'use'\n",
    "    ])\n",
    "    # Be careful of this\n",
    "    custom_stopwords.update([\n",
    "    'anything', 'every', 'around', 'two', 'end', 'us', 'ill', 'since', '1', 'theres', 'etc', 'getting'\n",
    "    ])\n",
    "    all_stopwords = stop_words.union(custom_stopwords)\n",
    "    all_stopwords.discard('love')  # Make sure \"love\" is retained\n",
    "    clean_tokens = [token for token in tokens if token not in all_stopwords]\n",
    "\n",
    "    clean_tokens = [token for token in clean_tokens if token not in topic_stopwords]\n",
    "\n",
    "    name_set = set(names.words())\n",
    "    name_set.discard('Love')\n",
    "    clean_tokens = [token for token in clean_tokens if token.capitalize() not in name_set]\n",
    "\n",
    "    def get_wordnet_pos(tag):\n",
    "        if tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN  # fallback\n",
    "\n",
    "    if use_lemmanization:\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        tagged = pos_tag(clean_tokens)\n",
    "        clean_tokens = [lemmatizer.lemmatize(w, get_wordnet_pos(t)) for w, t in tagged]\n",
    "    \n",
    "    return ' '.join(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = X_train.apply(preprocess_data)\n",
    "X_valid_clean = X_valid.apply(preprocess_data)\n",
    "X_test_clean = X_test.apply(preprocess_data)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=10000)\n",
    "tfidf.fit(pd.concat([X_train_clean, X_valid_clean]))\n",
    "\n",
    "X_train_tfidf = tfidf.transform(X_train_clean)\n",
    "X_valid_tfidf = tfidf.transform(X_valid_clean)\n",
    "X_test_tfidf = tfidf.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69453a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')\n",
    "\n",
    "X_train_source_ohe = ohe.fit_transform(source_train.to_numpy().reshape(-1, 1))\n",
    "X_valid_source_ohe = ohe.transform(source_valid.to_numpy().reshape(-1, 1))\n",
    "X_test_source_ohe = ohe.transform(source_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# 4. Concatenate TF-IDF and OHE\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_source_ohe])\n",
    "X_valid_combined = hstack([X_valid_tfidf, X_valid_source_ohe])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_source_ohe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe4dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Build multi-label logistic regression, CalibratedClassifierCV is ineffective\n",
    "logreg = LogisticRegression(max_iter=1000, solver='liblinear', class_weight='balanced')  # liblinear is good for small/medium datasets\n",
    "model = MultiOutputClassifier(logreg)\n",
    "model.fit(X_train_combined, y_train)\n",
    "y_pred = model.predict(X_valid_combined)\n",
    "print(classification_report(y_valid, y_pred, target_names=y_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1112aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('ocean_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "# Save the OneHotEncoder if used\n",
    "with open('source_ohe.pkl', 'wb') as f:\n",
    "    pickle.dump(ohe, f)\n",
    "\n",
    "with open(\"topic_stopwords.pkl\", \"wb\") as f:\n",
    "    pickle.dump(topic_stopwords, f)\n",
    "\n",
    "# # Save trait list (optional)\n",
    "# with open('traits_list.pkl', 'wb') as f:\n",
    "#     pickle.dump(traits, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words_per_trait(model, tfidf, traits, top_n=10):\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    tfidf_len = len(feature_names)\n",
    "\n",
    "    for i, trait in enumerate(traits):\n",
    "        print(f\"\\nTop words for {trait}:\")\n",
    "        coef = model.estimators_[i].coef_[0][:tfidf_len]  # Only use TF-IDF weights\n",
    "        top_indices = np.argsort(coef)[-top_n:]\n",
    "        top_words = feature_names[top_indices]\n",
    "        print(top_words[::-1])  # Reverse for descending order\n",
    "\n",
    "get_top_words_per_trait(model, tfidf, traits, top_n=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4613ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_traits_from_text(text, source, model, tfidf, ohe, traits, threshold=0.4, margin=0.02):\n",
    "    clean_text = preprocess_data(text)\n",
    "    tfidf_vec = tfidf.transform([clean_text])\n",
    "    tokens = tfidf.inverse_transform(tfidf_vec)[0]\n",
    "\n",
    "    # Handle missing or unknown source\n",
    "    if source is None:\n",
    "        source = \"unknown\"\n",
    "    source_encoded = ohe.transform([[source]])  # 2D array\n",
    "\n",
    "    from scipy.sparse import hstack\n",
    "    combined_vec = hstack([tfidf_vec, source_encoded])\n",
    "\n",
    "    # Get raw weights and scores\n",
    "    weights = [clf.coef_[0] for clf in model.estimators_]\n",
    "    scores = np.array([clf.intercept_[0] for clf in model.estimators_])\n",
    "\n",
    "    for i, trait_weights in enumerate(weights):\n",
    "        scores[i] += combined_vec.dot(trait_weights.T)[0]\n",
    "\n",
    "    probs = 1 / (1 + np.exp(-scores))\n",
    "    probas_rounded = np.round(probs, 3)\n",
    "    trait_probs = dict(zip(traits, probas_rounded))\n",
    "\n",
    "    top_idx = np.argmax(probs)\n",
    "    top_score = probs[top_idx]\n",
    "    predicted_traits = sorted([\n",
    "        traits[i] for i, p in enumerate(probs)\n",
    "        if p >= threshold and (top_score - p <= margin)\n",
    "    ])\n",
    "\n",
    "    trait_thresholds = {\n",
    "        'Extraversion': 0.4,\n",
    "        'Neuroticism': 0.4,\n",
    "        'Agreeable': 0.4,\n",
    "        'Conscientiousness': 0.4,\n",
    "        'Openness': 0.5\n",
    "    }\n",
    "    binary_vector = [\n",
    "        1 if probs[i] >= trait_thresholds[traits[i]] else 0\n",
    "        for i in range(len(traits))\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"predicted_traits\": predicted_traits,\n",
    "        \"probabilities\": trait_probs,\n",
    "        \"binary_vector\": binary_vector\n",
    "    }\n",
    "\n",
    "# Manually predict something extreme\n",
    "text = \"I like solving puzzles. It encourages me to use my logical thinking skills. I am also a neat person\"\n",
    "#text = \"I hate going out, especially to parties.\"\n",
    "#text = 'I loved going out to meet new people'\n",
    "#text = 'I\\'m anxious and worried.'\n",
    "#text = 'i like meeting new people, making nice notes, experiencing new adventures. new experiences drive me/motivate me.'\n",
    "#text = \"Well, I\\'m not really sure what types of things I\\'m supposed to be saying. I miss my boyfriend so much. I hope he has a safe trip home. I hope he doesn\\'t fall asleep. I feel really sleepy myself. I hope I can stay awake for this twenty minutes. Time seems to go by so slowly when you\\'re sleepy. Especially when school work is involved. I wish I was a better typer. It is so hard to just think normally when you\\'re typing on a computer. People probably think I\\'m not a very interesting person. I try to be, but I think I was born to be boring. Be boring and study my life away. I really don\\'t mean to be so studious. I mean I want to do well in school, but I think I\\'m too caught up in it. Everything makes me nervous. It is so strange because even though I know this isn't going to be grad, I feel nervous about doing it wrong or not doing a good job. I miss my family and my friends. I don't think I appreciated them enough when I was home. It is so hard to build a friendship up from scratch. It took years to be so close to them, and now I have to start all over. I'm truly lucky to have people that share all of my memories and understand all of my feelings. I wonder if they miss me as much as I miss them. I'm so paranoid. I'm always concerned that people are deceiving me in relationships. What if they don't mean love in the same way that I do?  I hate being hurt. I like to be in control and be omniscient. I like to have the upper hand with people. Unfortunately,  I think most of the time I'm the vulnerable one. Is that normal?  Probably. If I tell myself that enough I might believe it. Could someone really love someone enough that they would die for them if they had to. So many songs make that claim. It must be a truly amazing love. I am still in awe when I think about what Jesus did for me and everyone else. He died a most humiliating and painful death so we wouldn't have to. What love!  How sad though to think that not everyone accepts it!  I feel so guilty when talking to someone that doesn't accept it. I feel like there is something I could say to solve it, but I just don't know what. I know I'm not doing everything I could for Christ, and therefore not being quite good enough. I know I can't be perfect, but I try so hard to be. It feels that I come up short a lot in my life. It is so stressful. I'm probably going to die at an early age because of it. I can't stop though. Kale is so wonderful. He would do anything for me. I can't imagine anyone loving me that much unless they have to. My parents have to, but he doesn't. It is amazing.\"\n",
    "#text = \"My child likes solving puzzles, he is quite the logical boy!\"\n",
    "#text = \"My child always cries and whines.\"\n",
    "#text = 'My child cries and whines a lot.'\n",
    "\n",
    "#text = 'Thinking deeply and imagining new worlds is what inspires me most.'\n",
    "\n",
    "#text = 'My child neatly arranges books by size and subject without being told.'\n",
    "#text = 'Even if he’s upset, he speaks kindly and listens to others.'\n",
    "#text = 'He comforts others when they’re feeling left out or down.'\n",
    "text = 'She’s extremely punctual and plans everything in advance.'\n",
    "\n",
    "predict_traits_from_text(text, None, model, tfidf, ohe, traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3970163",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I hate going out, especially to parties.\"\n",
    "#text = 'I\\m anxious and worried.'\n",
    "#text = \"Well, I\\'m not really sure what types of things I\\'m supposed to be saying. I miss my boyfriend so much. I hope he has a safe trip home. I hope he doesn\\'t fall asleep. I feel really sleepy myself. I hope I can stay awake for this twenty minutes. Time seems to go by so slowly when you\\'re sleepy. Especially when school work is involved. I wish I was a better typer. It is so hard to just think normally when you\\'re typing on a computer. People probably think I\\'m not a very interesting person. I try to be, but I think I was born to be boring. Be boring and study my life away. I really don\\'t mean to be so studious. I mean I want to do well in school, but I think I\\'m too caught up in it. Everything makes me nervous. It is so strange because even though I know this isn't going to be grad, I feel nervous about doing it wrong or not doing a good job. I miss my family and my friends. I don't think I appreciated them enough when I was home. It is so hard to build a friendship up from scratch. It took years to be so close to them, and now I have to start all over. I'm truly lucky to have people that share all of my memories and understand all of my feelings. I wonder if they miss me as much as I miss them. I'm so paranoid. I'm always concerned that people are deceiving me in relationships. What if they don't mean love in the same way that I do?  I hate being hurt. I like to be in control and be omniscient. I like to have the upper hand with people. Unfortunately,  I think most of the time I'm the vulnerable one. Is that normal?  Probably. If I tell myself that enough I might believe it. Could someone really love someone enough that they would die for them if they had to. So many songs make that claim. It must be a truly amazing love. I am still in awe when I think about what Jesus did for me and everyone else. He died a most humiliating and painful death so we wouldn't have to. What love!  How sad though to think that not everyone accepts it!  I feel so guilty when talking to someone that doesn't accept it. I feel like there is something I could say to solve it, but I just don't know what. I know I'm not doing everything I could for Christ, and therefore not being quite good enough. I know I can't be perfect, but I try so hard to be. It feels that I come up short a lot in my life. It is so stressful. I'm probably going to die at an early age because of it. I can't stop though. Kale is so wonderful. He would do anything for me. I can't imagine anyone loving me that much unless they have to. My parents have to, but he doesn't. It is amazing.\"\n",
    "#text = \"I like solving puzzles. It encourages me to use my logical thinking skills. I am also a neat person\"\n",
    "#text = 'I really love going out to meet new people'\n",
    "#text = 'i like meeting new people, making nice notes, experiencing new adventures. new experiences drive me/motivate me.'\n",
    "text = \"My child likes solving puzzles, he is quite the logical boy!\"\n",
    "#text = \"My child always cries and whines.\"\n",
    "#text = 'My child cries and whines a lot.'\n",
    "text = 'My child is full of energy, always talking to new people and making friends everywhere he goes.'\n",
    "#text = 'She always helps her classmates and makes sure everyone feels included during playtime'\n",
    "\n",
    "text = 'Thinking deeply and imagining new worlds is what inspires me most.'\n",
    "text = 'I make checklists for every task and feel fulfilled ticking them off.'\n",
    "text = 'She’s extremely punctual and plans everything in advance.'\n",
    "text = 'My child neatly arranges books by size and subject without being told.'\n",
    "text = 'Even if he’s upset, he speaks kindly and listens to others.'\n",
    "text = 'He comforts others when they’re feeling left out or down.'\n",
    "\n",
    "# Preprocess\n",
    "clean_text = preprocess_data(text)\n",
    "print(\"Cleaned:\", clean_text)\n",
    "\n",
    "# TF-IDF tokens used\n",
    "vector = tfidf.transform([clean_text])\n",
    "tokens = tfidf.inverse_transform(vector)[0]\n",
    "print(\"Matched Tokens:\", tokens)\n",
    "\n",
    "# Probabilities\n",
    "# probs = model.predict_proba(vector)\n",
    "# trait_probs = {traits[i]: float(probs[i][0][1]) for i in range(len(traits))}\n",
    "# print(\"Trait Probabilities:\", trait_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632455a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_token_weights_across_traits(tokens_to_check, model, tfidf, traits):\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    weights_matrix = []\n",
    "\n",
    "    for clf in model.estimators_:\n",
    "        weights = clf.coef_[0][:len(feature_names)]  # Exclude OHE source weights\n",
    "        token_weights = []\n",
    "        for token in tokens_to_check:\n",
    "            if token in feature_names:\n",
    "                idx = np.where(feature_names == token)[0][0]\n",
    "                token_weights.append(weights[idx])\n",
    "            else:\n",
    "                token_weights.append(0.0)\n",
    "        weights_matrix.append(token_weights)\n",
    "\n",
    "    # Convert to numpy array for seaborn\n",
    "    weights_array = np.array(weights_matrix)\n",
    "\n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(weights_array, annot=True, xticklabels=tokens_to_check, yticklabels=traits, cmap='coolwarm')\n",
    "    plt.title(\"Token Weights Across Traits (Logistic Regression Coefficients)\")\n",
    "    plt.xlabel(\"Tokens\")\n",
    "    plt.ylabel(\"Traits\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "tokens_to_check = ['meet', 'new', 'love', 'party', 'especially', 'hate', 'tidy']\n",
    "tokens_to_check = tokens.tolist()\n",
    "tokens_to_analyze = [\n",
    "    'panic',\n",
    "    'suffer',\n",
    "    'weep',\n",
    "    'complain',\n",
    "    'whine',\n",
    "    'cry',\n",
    "    'yell',\n",
    "    'shout',\n",
    "    'solve',\n",
    "    'moody',\n",
    "    'anxious',\n",
    "    'scared',\n",
    "    'calm',\n",
    "    'breathe',\n",
    "    'logical',\n",
    "    'quiet',\n",
    "    'solve',\n",
    "    'neat',\n",
    "    'child',\n",
    "    'like',\n",
    "    'boy',\n",
    "    'love',\n",
    "    'hate',\n",
    "    'party',\n",
    "    'meeting',\n",
    "    'social',\n",
    "    'overwhelm',\n",
    "    'together',\n",
    "    'fun',\n",
    "    'group',\n",
    "    'detail',\n",
    "    'control',\n",
    "    'relax',\n",
    "    'creative',\n",
    "    'curious',\n",
    "    'adventure',\n",
    "    'philosophy',\n",
    "    'organized',\n",
    "    'explore'\n",
    "]\n",
    "visualize_token_weights_across_traits(tokens_to_check, model, tfidf, traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1361af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trait, clf in zip(traits, model.estimators_):\n",
    "    print(f\"{trait} bias (intercept): {clf.intercept_[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
